---
title: "Project3"
author: 
date:
output: html_document
---

## Front Matter
```{r}
library(tidyverse)
library(readxl)
cod <- read_excel('CODGames2_mp.xlsx', sheet = 1)
```

# data cleaning (same procedure as mp1 and mp2 )
```{r}
cod_working <- cod %>%
  rename(
    map1 = Map1,
    map2 = Map2,
    choice = Choice,
    map_vote = MapVote,
    date = Date,
    full_partial = FullPartial,
    result = Result,
    eliminations = Eliminations,
    deaths = Deaths,
    score = Score,
    damage = Damage,
    total_xp = TotalXP,
    primary_weapon = PrimaryWeapon,
    xp_multiplier = XPType, # call this multiplier, will convert in next command
    did_player_vote = DidPlayerVote,
    game_type = GameType,
    confirms = Confirms,
    denies = Denies,
    objectives = Objectives,
    objective_kills = ObjectiveKills,
    captures = Captures,
    diffuses = Diffuses,
    plants = Plants,
    detonates = Detonates,
    deposits = Deposits,
    time_sec = Time_Sec,
    time_min = Time_Min
  ) %>%
  mutate(  # for now, only mutating variables we think are important
    map1 = as.factor(map1), 
    map2 = as.factor(map2),
    choice = as.factor(choice),
    full_partial = as.factor(full_partial),
    primary_weapon = as.factor(primary_weapon),
    xp_multiplier = if_else(xp_multiplier == '10% Boost', 1.10, 2.10),
    did_player_vote = as.logical(if_else(did_player_vote == 'Yes',1,0)),
  ) %>%
  separate(result, into = c('team_result', 'other_team_result'), sep = '-', extra = 'merge', convert = TRUE) 

# drop columns with a lot of NA values, so count the values first 
apply(cod_working, MARGIN = 2, FUN = function(x) sum(is.na(x))) # counts total NA in columns

# since NA values are either < 50 or >200 drop all columns with more than 200 NA values
cod_working <- cod_working %>%
  select(where(~ sum(is.na(.)) < 200))

```



1. In order to help you to understand more of the variables in the dataset, this problem uses ‘TotalXP’,
‘XPType’ and ‘FullPartial’.

• The ‘FullPartial’ variable takes on two values: Full or Partial. These values are a reference as to
whether the player participated in the full match or only a part of the match. (Sometimes when
joining a new game, a player is added to a match that is already in progress. This is indicated by a
value of Partial in the FullPartial variable.) Since it is not fair to compare the total experience
points earned (TotalXP) for a match in which the player only participated in a fraction of the
match to the TotalXP for a match in which the player participated in the entire match, we want to
remove the cases in which the player only participated in a fraction of the match.


```{r}
cod_working <-
  cod_working %>%
  filter(full_partial == "Full")
```


• The type of experience points earned (‘XPType’) variable takes on one of two possible values:
10% Boost and Double XP + 10%. This variable is a reference to the way that the game calculates
the number of experience points (XP) As an example, suppose that capturing an enemy location
earns the player 50 experience point.s (XP). With the 10% Boost scoring, the player earns 55
experience points (50 + 50*0.1). Under the Double XP + 10%, the player would earn 105
experience points (50*2 + 50*0.1).

After removing the cases in which the player only participated in a fraction of the match, create side-by-
side boxplots showing the relationship between TotalXP and XPType. (Be sure to use proper axis labels
rather than the variable names.) Supplement the plots with summary statistics of TotalXP for each level of
XPType. What have you learned about the relationship between XPType and TotalXP?

```{r}
boxplot(total_xp ~ xp_multiplier, data = cod_working,
        main = "Total Experience Points by XP Boost",
        xlab = "Type of XP Boost",
        ylab = "Total Experience Points")

```

```{r}

cod_working %>%
  group_by(xp_multiplier) %>%
  summarise(
    count = n(),
    min = min(total_xp),
    q1 = quantile(total_xp, 0.25),
    median = median(total_xp),
    mean = mean(total_xp),
    q3 = quantile(total_xp, 0.75),
    max = max(total_xp),
    sd = sd(total_xp)
  )

```


2. Suppose we wish to build an appropriate model for modeling the Score variable for games in which the
player participated in the full match of a HC – TDM game type. We wish to answer the following
research question: Of the predictors total XP, eliminations, deaths, damage, XPType, and whether the
player’s team won, which should be included in a model for the Score? To answer this, you will have to
create a new variable that indicates whether the player was on the winning team or not. NOTE: Since this
is an inference question and we are not worried about how well the model will generalize to new data,
there is no need to do a training/validation split in this problem.

```{r, message = FALSE}
# import libraries for this question
library(glmnet)
library(rpart)
library(rattle)

# add column to indicate if players team won (strictly larger)
cod_working$winning_team <- if_else(cod_working$team_result > cod_working$other_team_result, 1, 0)
# new df just for this question
cod_q2 <- cod_working %>% filter(game_type == 'HC - TDM')
```

a. Implement LASSO regression and one other feature selection procedure that we covered in Lecture
15. Include relevant plots, a discussion on which value of lambda you selected, the estimated
equation from LASSO and the estimated equation from the second method. Discuss/compare the
results of LASSO with those of the other method.

Since we want to implement a lasso model and also select a value of lambda, it makes sense to use a cross validation approach to get the best lasso model.  
```{r}
# preparing data before modeling. (we will use xp_multiplier to stand as the xp_type variable since they are functionally the same thing)
xmat = model.matrix(score ~ total_xp + eliminations + deaths + damage + xp_multiplier + winning_team, data = cod_q2)[,-1]
ymat <- cod_q2$score
# implementing logistic regression with CV LASSO selection
set.seed(123) 
lasso_model <- cv.glmnet(x = xmat, y = ymat, lambda = NULL, standardize = T, nfolds = 10)
plot(lasso_model)
```

```{r}
# get coefficients from the lasso model with the minimum binomial deviance
lasso_coeff <- predict(lasso_model, s = lasso_model$lambda.min, type = 'coefficients')
lasso_coeff
```

```{r}
# implementing glm with backwards best subset selection with AIC scoring
null_model = lm(score ~ 1, data = cod_q2)
full_model = lm(score ~ total_xp + eliminations + deaths + damage + xp_multiplier + winning_team, data = cod_q2)

step(object = full_model, scope = list(lower = null_model, upper = full_model), method = 'backwards')
```

b. (This material will be finished in lecture by Wednesday, April 23.) Build a regression tree for
predicting Score using total XP, eliminations, deaths, damage, XPType, and whether the player’s
team won. Specify that each node must contain at least 15 observations. Display the tree and
report the variables associated with the 3 highest variable importance values. (Include the variable
importance values when mentioning the variables.)


```{r}
RegTree <- rpart(score ~ total_xp + eliminations + deaths + damage + xp_multiplier + Outcome,
                 method = "anova",
                 data = cod_working,
                 minbucket = 15)

fancyRpartPlot(RegTree,
               cex = .7)

RegTree$variable.importance
```

c. When building linear regression models, we often wish to determine which variables are the most
important. One way of doing this is to look at the magnitude (absolute value) of the estimated
coefficients for the regression model built using standardized inputs (centered to have a mean of 0
and a standard deviation of 1). Based on the variables selected by the other feature selection
procedure from part a. (in other words, not the LASSO model), standardize the inputs, build the
regression model, report the estimated equation, and report the 3 most important variables based
on the magnitude (absolute value) of the estimated coefficients. How does this compare to the
most important variables based on the regression tree?
